url <- str_glue("https://www150.statcan.gc.ca/t1/tbl1/en/",
"dtl!downloadDbLoadingData.action?pid=1710000901&",
"latestN=50&startDate=&endDate=&csvLocale=en&",
"selectedMembers=",
URLencode("[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]]",
reserved = TRUE))
# Read the CSV data from the specified URL
data <- read_csv(url)
# Cleaning and removing columns
cleaned_data <- data %>%
select(REF_DATE, GEO, VALUE) %>%  # Select specific columns
filter(!is.na(GEO))  # Remove rows with missing GEO values
# Calculate GrowthRate per 1000
# cleaned_data <- cleaned_data %>%
#     group_by(GEO) %>%
#     mutate(GrowthRate = (VALUE - lag(VALUE))/lag(VALUE) * 10000) %>%
#     ungroup()
cleaned_data <- cleaned_data %>%
group_by(GEO) %>%
GrowthRate = (VALUE/min(VALUE)) * 100 %>%
ungroup()
# Load the required libraries and dependencies
source("dependencies.R")
# Load your data
url <- str_glue("https://www150.statcan.gc.ca/t1/tbl1/en/",
"dtl!downloadDbLoadingData.action?pid=1710000901&",
"latestN=50&startDate=&endDate=&csvLocale=en&",
"selectedMembers=",
URLencode("[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]]",
reserved = TRUE))
# Read the CSV data from the specified URL
data <- read_csv(url)
# Cleaning and removing columns
cleaned_data <- data %>%
select(REF_DATE, GEO, VALUE) %>%  # Select specific columns
filter(!is.na(GEO))  # Remove rows with missing GEO values
# Calculate GrowthRate per 1000
# cleaned_data <- cleaned_data %>%
#     group_by(GEO) %>%
#     mutate(GrowthRate = (VALUE - lag(VALUE))/lag(VALUE) * 10000) %>%
#     ungroup()
cleaned_data <- cleaned_data %>%
group_by(GEO) %>%
mutate(GrowthRate = (cleaned_data$VALUE/min(cleaned_data$VALUE)) * 100) %>%
ungroup()
# Load the required libraries and dependencies
source("dependencies.R")
# Load your data
url <- str_glue("https://www150.statcan.gc.ca/t1/tbl1/en/",
"dtl!downloadDbLoadingData.action?pid=1710000901&",
"latestN=50&startDate=&endDate=&csvLocale=en&",
"selectedMembers=",
URLencode("[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]]",
reserved = TRUE))
# Read the CSV data from the specified URL
data <- read_csv(url)
# Cleaning and removing columns
cleaned_data <- data %>%
select(REF_DATE, GEO, VALUE) %>%  # Select specific columns
filter(!is.na(GEO))  # Remove rows with missing GEO values
# Calculate GrowthRate per 1000
# cleaned_data <- cleaned_data %>%
#     group_by(GEO) %>%
#     mutate(GrowthRate = (VALUE - lag(VALUE))/lag(VALUE) * 10000) %>%
#     ungroup()
# Group by GEO and calculate GrowthRate within each group
cleaned_data <- cleaned_data %>%
group_by(GEO) %>%
mutate(min_value = min(VALUE),  # Calculate minimum value within each group
GrowthRate = (VALUE / min_value - 1) * 100) %>%
ungroup()  # Ungroup the data to remove grouping
# Remove the temporary min_value column if not needed
cleaned_data <- cleaned_data %>%
select(-min_value)
# Rename the columns for readability
cleaned_data <- cleaned_data %>%
rename("Reference period" = REF_DATE, Geography = GEO, Population = VALUE, "Growth rate" = GrowthRate)
View(cleaned_data)
# # Remove the temporary min_value column if not needed
# cleaned_data <- cleaned_data %>%
#     select(-min_value)
# Load the required libraries and dependencies
source("dependencies.R")
# Load your data
url <- str_glue("https://www150.statcan.gc.ca/t1/tbl1/en/",
"dtl!downloadDbLoadingData.action?pid=1710000901&",
"latestN=50&startDate=&endDate=&csvLocale=en&",
"selectedMembers=",
URLencode("[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]]",
reserved = TRUE))
# Read the CSV data from the specified URL
data <- read_csv(url)
# Cleaning and removing columns
cleaned_data <- data %>%
select(REF_DATE, GEO, VALUE) %>%  # Select specific columns
filter(!is.na(GEO))  # Remove rows with missing GEO values
# Calculate GrowthRate per 1000
# cleaned_data <- cleaned_data %>%
#     group_by(GEO) %>%
#     mutate(GrowthRate = (VALUE - lag(VALUE))/lag(VALUE) * 10000) %>%
#     ungroup()
# Group by GEO and calculate GrowthRate within each group
cleaned_data <- cleaned_data %>%
group_by(GEO) %>%
mutate(min_value = min(VALUE),  # Calculate minimum value within each group
GrowthRate = (VALUE / min_value - 1) * 100) %>%
ungroup()  # Ungroup the data to remove grouping
# # Remove the temporary min_value column if not needed
# cleaned_data <- cleaned_data %>%
#     select(-min_value)
# Rename the columns for readability
cleaned_data <- cleaned_data %>%
rename("Reference period" = REF_DATE, Geography = GEO, Population = VALUE, "Growth rate" = GrowthRate)
View(cleaned_data)
# Load the required libraries and dependencies
source("dependencies.R")
# Load your data
url <- str_glue("https://www150.statcan.gc.ca/t1/tbl1/en/",
"dtl!downloadDbLoadingData.action?pid=1710000901&",
"latestN=&startDate=2011-01&endDate=&csvLocale=en&",
"selectedMembers=",
URLencode("[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]]",
reserved = TRUE))
# Read the CSV data from the specified URL
data <- read_csv(url)
# Cleaning and removing columns
cleaned_data <- data %>%
select(REF_DATE, GEO, VALUE) %>%  # Select specific columns
filter(!is.na(GEO))  # Remove rows with missing GEO values
# Calculate GrowthRate per 1000
# cleaned_data <- cleaned_data %>%
#     group_by(GEO) %>%
#     mutate(GrowthRate = (VALUE - lag(VALUE))/lag(VALUE) * 10000) %>%
#     ungroup()
# Group by GEO and calculate GrowthRate within each group
cleaned_data <- cleaned_data %>%
group_by(GEO) %>%
mutate(min_value = min(VALUE),  # Calculate minimum value within each group
GrowthRate = (VALUE / min_value - 1) * 100) %>%
ungroup()  # Ungroup the data to remove grouping
# # Remove the temporary min_value column if not needed
# cleaned_data <- cleaned_data %>%
#     select(-min_value)
# Rename the columns for readability
cleaned_data <- cleaned_data %>%
rename("Reference period" = REF_DATE, Geography = GEO, Population = VALUE, "Growth rate" = GrowthRate)
View(cleaned_data)
# Group by GEO and calculate GrowthRate within each group
cleaned_data <- cleaned_data %>%
group_by(GEO) %>%
mutate(min_value = min(VALUE),  # Calculate minimum value within each group
GrowthRate = (VALUE / min_value) * 100) %>%
ungroup()  # Ungroup the data to remove grouping
# Load the required libraries and dependencies
source("dependencies.R")
# Load your data
url <- str_glue("https://www150.statcan.gc.ca/t1/tbl1/en/",
"dtl!downloadDbLoadingData.action?pid=1710000901&",
"latestN=&startDate=2011-01&endDate=&csvLocale=en&",
"selectedMembers=",
URLencode("[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]]",
reserved = TRUE))
# Read the CSV data from the specified URL
data <- read_csv(url)
# Cleaning and removing columns
cleaned_data <- data %>%
select(REF_DATE, GEO, VALUE) %>%  # Select specific columns
filter(!is.na(GEO))  # Remove rows with missing GEO values
# Calculate GrowthRate per 1000
# cleaned_data <- cleaned_data %>%
#     group_by(GEO) %>%
#     mutate(GrowthRate = (VALUE - lag(VALUE))/lag(VALUE) * 10000) %>%
#     ungroup()
# Group by GEO and calculate GrowthRate within each group
cleaned_data <- cleaned_data %>%
group_by(GEO) %>%
mutate(min_value = min(VALUE),  # Calculate minimum value within each group
GrowthRate = (VALUE / min_value) * 100) %>%
ungroup()  # Ungroup the data to remove grouping
# # Remove the temporary min_value column if not needed
# cleaned_data <- cleaned_data %>%
#     select(-min_value)
# Rename the columns for readability
cleaned_data <- cleaned_data %>%
rename("Reference period" = REF_DATE, Geography = GEO, Population = VALUE, "Growth rate" = GrowthRate)
View(cleaned_data)
# Load the required libraries and dependencies
source("dependencies.R")
# Load your data
url <- str_glue("https://www150.statcan.gc.ca/t1/tbl1/en/",
"dtl!downloadDbLoadingData.action?pid=1710000901&",
"latestN=&startDate=2011-01&endDate=&csvLocale=en&",
"selectedMembers=",
URLencode("[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]]",
reserved = TRUE))
# Read the CSV data from the specified URL
data <- read_csv(url)
# Cleaning and removing columns
cleaned_data <- data %>%
select(REF_DATE, GEO, VALUE) %>%  # Select specific columns
filter(!is.na(GEO))  # Remove rows with missing GEO values
# Calculate GrowthRate per 1000
# cleaned_data <- cleaned_data %>%
#     group_by(GEO) %>%
#     mutate(GrowthRate = (VALUE - lag(VALUE))/lag(VALUE) * 10000) %>%
#     ungroup()
# Find the minimum date for each group (GEO)
min_dates <- cleaned_data %>%
group_by(GEO) %>%
summarize(min_date = min(REF_DATE))
# Merge the minimum dates back into the original dataset
cleaned_data <- cleaned_data %>%
left_join(min_dates, by = "GEO")
# Calculate the minimum value for each minimum date within each group
min_date_values <- cleaned_data %>%
group_by(GEO, min_date) %>%
summarize(min_value = min(VALUE))
# Merge the minimum date values back into the original dataset
cleaned_data <- cleaned_data %>%
left_join(min_date_values, by = c("GEO", "min_date"))
# Calculate the growth percentage for each value relative to the minimum value within the same minimum date and group
cleaned_data <- cleaned_data %>%
mutate(GrowthRate = (VALUE / min_value) * 100)
# Remove the temporary columns if not needed
cleaned_data <- cleaned_data %>%
select(-min_date, -min_value)
# Rename the columns for readability
cleaned_data <- cleaned_data %>%
rename("Reference period" = REF_DATE, Geography = GEO, Population = VALUE, "Growth rate" = GrowthRate)
View(cleaned_data)
# Load the required libraries and dependencies
source("dependencies.R")
# Load your data
url <- str_glue("https://www150.statcan.gc.ca/t1/tbl1/en/",
"dtl!downloadDbLoadingData.action?pid=1710000901&",
"latestN=&startDate=2011-01&endDate=&csvLocale=en&",
"selectedMembers=",
URLencode("[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]]",
reserved = TRUE))
# Read the CSV data from the specified URL
data <- read_csv(url)
# Cleaning and removing columns
cleaned_data <- data %>%
select(REF_DATE, GEO, VALUE) %>%  # Select specific columns
filter(!is.na(GEO))  # Remove rows with missing GEO values
# Calculate GrowthRate per 1000
# cleaned_data <- cleaned_data %>%
#     group_by(GEO) %>%
#     mutate(GrowthRate = (VALUE - lag(VALUE))/lag(VALUE) * 10000) %>%
#     ungroup()
# Find the minimum date for each group (GEO)
min_dates <- cleaned_data %>%
group_by(GEO) %>%
summarize(min_date = min(REF_DATE))
# Merge the minimum dates back into the original dataset
cleaned_data <- cleaned_data %>%
left_join(min_dates, by = "GEO")
# Calculate the minimum value for each minimum date within each group
min_date_values <- cleaned_data %>%
group_by(GEO, min_date) %>%
summarize(min_value = min(VALUE))
# Merge the minimum date values back into the original dataset
cleaned_data <- cleaned_data %>%
left_join(min_date_values, by = c("GEO", "min_date"))
# Calculate the growth percentage for each value relative to the minimum value within the same minimum date and group
cleaned_data <- cleaned_data %>%
mutate(GrowthRate = (VALUE / min_value) * 100)
View(cleaned_data)
# Load the required libraries and dependencies
source("dependencies.R")
# Load your data
url <- str_glue("https://www150.statcan.gc.ca/t1/tbl1/en/",
"dtl!downloadDbLoadingData.action?pid=1710000901&",
"latestN=&startDate=2011-01&endDate=&csvLocale=en&",
"selectedMembers=",
URLencode("[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]]",
reserved = TRUE))
# Read the CSV data from the specified URL
data <- read_csv(url)
# Cleaning and removing columns
cleaned_data <- data %>%
select(REF_DATE, GEO, VALUE) %>%  # Select specific columns
filter(!is.na(GEO))  # Remove rows with missing GEO values
# Calculate GrowthRate per 1000
# cleaned_data <- cleaned_data %>%
#     group_by(GEO) %>%
#     mutate(GrowthRate = (VALUE - lag(VALUE))/lag(VALUE) * 10000) %>%
#     ungroup()
# Find the minimum date for each group (GEO)
min_dates <- cleaned_data %>%
group_by(GEO) %>%
summarize(min_date = min(REF_DATE))
# Merge the minimum dates back into the original dataset
cleaned_data <- cleaned_data %>%
left_join(min_dates, by = "GEO")
# Filter the dataset to get the rows matching the minimum date within each group
min_date_values <- cleaned_data %>%
filter(REF_DATE == min_date) %>%
select(GEO, min_date, min_value = VALUE) %>%
distinct()  # Remove duplicate rows
# Merge the minimum date values back into the original dataset
cleaned_data <- cleaned_data %>%
left_join(min_date_values, by = c("GEO", "min_date"))
# Calculate the growth percentage for each value relative to the minimum value within the same minimum date and group
cleaned_data <- cleaned_data %>%
mutate(GrowthRate = (VALUE / min_value) * 100)
View(cleaned_data)
# Load the required libraries and dependencies
source("dependencies.R")
# Load your data
url <- str_glue("https://www150.statcan.gc.ca/t1/tbl1/en/",
"dtl!downloadDbLoadingData.action?pid=1710000901&",
"latestN=&startDate=2011-01&endDate=&csvLocale=en&",
"selectedMembers=",
URLencode("[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]]",
reserved = TRUE))
# Read the CSV data from the specified URL
data <- read_csv(url)
# Cleaning and removing columns
cleaned_data <- data %>%
select(REF_DATE, GEO, VALUE) %>%  # Select specific columns
filter(!is.na(GEO))  # Remove rows with missing GEO values
# Calculate GrowthRate per 1000
# cleaned_data <- cleaned_data %>%
#     group_by(GEO) %>%
#     mutate(GrowthRate = (VALUE - lag(VALUE))/lag(VALUE) * 10000) %>%
#     ungroup()
# Find the minimum date for each group (GEO)
min_dates <- cleaned_data %>%
group_by(GEO) %>%
summarize(min_date = min(REF_DATE))
# Merge the minimum dates back into the original dataset
cleaned_data <- cleaned_data %>%
left_join(min_dates, by = "GEO")
# Filter the dataset to get the rows matching the minimum date within each group
min_date_values <- cleaned_data %>%
filter(REF_DATE == min_date) %>%
select(GEO, min_date, min_value = VALUE) %>%
distinct()  # Remove duplicate rows
# Merge the minimum date values back into the original dataset
cleaned_data <- cleaned_data %>%
left_join(min_date_values, by = c("GEO", "min_date"))
# Calculate the growth percentage for each value relative to the minimum value within the same minimum date and group
cleaned_data <- cleaned_data %>%
mutate(GrowthRate = (VALUE / min_value) * 100)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
View(cleaned_data)
# Load the required libraries and dependencies
source("dependencies.R")
# Load your data
url <- str_glue("https://www150.statcan.gc.ca/t1/tbl1/en/",
"dtl!downloadDbLoadingData.action?pid=1710000901&",
"latestN=&startDate=2011-01&endDate=&csvLocale=en&",
"selectedMembers=",
URLencode("[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]]",
reserved = TRUE))
# Read the CSV data from the specified URL
data <- read_csv(url)
# Cleaning and removing columns or keep the ones required
cleaned_data <- data %>%
select(REF_DATE, GEO, VALUE) %>%
filter(!is.na(GEO))
# Find the minimum date for each group (GEO) for calculating growth rate
min_dates <- cleaned_data %>%
group_by(GEO) %>%
summarize(min_date = min(REF_DATE))
# Merge the minimum dates back into the original dataset for calculating growth rate
cleaned_data <- cleaned_data %>%
left_join(min_dates, by = "GEO")
# Filter the dataset to get the rows matching the minimum date within each group for calculating growth rate
min_date_values <- cleaned_data %>%
filter(REF_DATE == min_date) %>%
select(GEO, min_date, min_value = VALUE) %>%
distinct()
# Merge the minimum date values back into the original dataset for calculating growth rate
cleaned_data <- cleaned_data %>%
left_join(min_date_values, by = c("GEO", "min_date"))
# Calculate the growth percentage for each value relative to the minimum value within the same minimum date and group
cleaned_data <- cleaned_data %>%
mutate(GrowthRate = (VALUE / min_value) * 100)
# Remove the temporary columns if not needed for clean up
cleaned_data <- cleaned_data %>%
select(-min_date, -min_value)
# Define a mapping of month numbers to quarter labels
quarter_mapping <- c("Q1", "Q2", "Q2", "Q3", "Q3", "Q3", "Q4", "Q4", "Q4", "Q1", "Q1", "Q1")
View(cleaned_data)
# Create a new column 'Quarter' with year and quarter label
cleaned_data <- cleaned_data %>%
mutate(Year = substr(REF_DATE, 1, 4),  # Extract the year
Quarter = paste(Year, quarter_mapping[as.integer(substr(REF_DATE, 6, 7))], sep = "-"))
View(cleaned_data)
# Load the required libraries and dependencies
source("dependencies.R")
# Load your data
url <- str_glue("https://www150.statcan.gc.ca/t1/tbl1/en/",
"dtl!downloadDbLoadingData.action?pid=1710000901&",
"latestN=&startDate=2011-01&endDate=&csvLocale=en&",
"selectedMembers=",
URLencode("[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]]",
reserved = TRUE))
# Read the CSV data from the specified URL
data <- read_csv(url)
# Cleaning and removing columns or keep the ones required
cleaned_data <- data %>%
select(REF_DATE, GEO, VALUE) %>%
filter(!is.na(GEO))
# Find the minimum date for each group (GEO) for calculating growth rate
min_dates <- cleaned_data %>%
group_by(GEO) %>%
summarize(min_date = min(REF_DATE))
# Merge the minimum dates back into the original dataset for calculating growth rate
cleaned_data <- cleaned_data %>%
left_join(min_dates, by = "GEO")
# Filter the dataset to get the rows matching the minimum date within each group for calculating growth rate
min_date_values <- cleaned_data %>%
filter(REF_DATE == min_date) %>%
select(GEO, min_date, min_value = VALUE) %>%
distinct()
# Merge the minimum date values back into the original dataset for calculating growth rate
cleaned_data <- cleaned_data %>%
left_join(min_date_values, by = c("GEO", "min_date"))
# Calculate the growth percentage for each value relative to the minimum value within the same minimum date and group
cleaned_data <- cleaned_data %>%
mutate(GrowthRate = (VALUE / min_value) * 100)
# Remove the temporary columns if not needed for clean up
cleaned_data <- cleaned_data %>%
select(-min_date, -min_value)
# Define a mapping of month numbers to quarter labels
quarter_mapping <- c("Q1", "Q1", "Q1", "Q2", "Q2", "Q2", "Q3", "Q3", "Q3", "Q4", "Q4", "Q4")
# Create a new column 'Quarter' with year and quarter label
cleaned_data <- cleaned_data %>%
mutate(Year = substr(REF_DATE, 1, 4),  # Extract the year
Quarter = paste(Year, quarter_mapping[as.integer(substr(REF_DATE, 6, 7))], sep = "-"))
View(cleaned_data)
View(cleaned_data)
# Rename the columns for readability
cleaned_data <- cleaned_data %>%
rename("Reference period" = Quarter, Geography = GEO, Population = VALUE, "Growth rate" = GrowthRate)
View(cleaned_data)
# Rename the columns for readability
cleaned_data <- cleaned_data %>%
rename("Reference period" = Quarter, Geography = GEO, Population = VALUE, "Growth rate" = GrowthRate)
runApp()
runApp()
runApp()
runApp()
runApp()
# Load the required libraries and dependencies
source("dependencies.R")
# Load your data
url <- str_glue("https://www150.statcan.gc.ca/t1/tbl1/en/",
"dtl!downloadDbLoadingData.action?pid=1710000901&",
"latestN=&startDate=2011-01&endDate=&csvLocale=en&",
"selectedMembers=",
URLencode("[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]]",
reserved = TRUE))
# Read the CSV data from the specified URL
data <- read_csv(url)
# Cleaning and removing columns or keep the ones required
cleaned_data <- data %>%
select(REF_DATE, GEO, VALUE) %>%
filter(!is.na(GEO))
# Find the minimum date for each group (GEO) for calculating growth rate
min_dates <- cleaned_data %>%
group_by(GEO) %>%
summarize(min_date = min(REF_DATE))
# Merge the minimum dates back into the original dataset for calculating growth rate
cleaned_data <- cleaned_data %>%
left_join(min_dates, by = "GEO")
# Filter the dataset to get the rows matching the minimum date within each group for calculating growth rate
min_date_values <- cleaned_data %>%
filter(REF_DATE == min_date) %>%
select(GEO, min_date, min_value = VALUE) %>%
distinct()
# Merge the minimum date values back into the original dataset for calculating growth rate
cleaned_data <- cleaned_data %>%
left_join(min_date_values, by = c("GEO", "min_date"))
# Calculate the growth percentage for each value relative to the minimum value within the same minimum date and group
cleaned_data <- cleaned_data %>%
mutate(GrowthRate = (VALUE / min_value) * 100)
# Remove the temporary columns if not needed for clean up
cleaned_data <- cleaned_data %>%
select(-min_date, -min_value)
# Define a mapping of month numbers to quarter labels
quarter_mapping <- c("Q1", "Q1", "Q1", "Q2", "Q2", "Q2", "Q3", "Q3", "Q3", "Q4", "Q4", "Q4")
# Create a new column 'Quarter' with year and quarter label
cleaned_data <- cleaned_data %>%
mutate(Year = substr(REF_DATE, 1, 4),  # Extract the year
Quarter = paste(Year, quarter_mapping[as.integer(substr(REF_DATE, 6, 7))], sep = "-"))
# Rename the columns for readability
cleaned_data <- cleaned_data %>%
rename("Reference period" = Quarter, Geography = GEO, Population = VALUE, "Growth rate" = GrowthRate)
# Define the desired column order
desired_order <- c("Reference period", "Geography", "Population", "Growth rate")
View(cleaned_data)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
